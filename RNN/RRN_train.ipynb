{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RRN WITH ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fib_seq(n,scaled_data=True):\n",
    "    seq = np.zeros(n)\n",
    "\n",
    "    fib_n1 = 0.0\n",
    "    fib_n = 1.0\n",
    "\n",
    "    for i in  range(n):\n",
    "        seq[i] = fib_n1 + fib_n\n",
    "        fib_n1 = fib_n\n",
    "        fib_n = seq[i]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) if scaled_data else None\n",
    "    if scaled_data:\n",
    "        seq = scaler.fit_transform(seq.reshape(-1,1)).flatten()\n",
    "    \n",
    "    return seq ,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01136364 0.02272727 0.04545455 0.07954545 0.13636364\n",
      " 0.22727273 0.375      0.61363636 1.        ]\n"
     ]
    }
   ],
   "source": [
    "seq , scaler = get_fib_seq(10)\n",
    "print(seq)\n",
    "# print(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fib_XY(total_fib_numbers, time_step, train_percent, scaled_data=True):\n",
    "    dat, scaler = get_fib_seq(total_fib_numbers, scaled_data)\n",
    "    Y_ind = np.arange(time_step, len(dat), 1)\n",
    "    \n",
    "\n",
    "    Y = dat[Y_ind]\n",
    "    rows_x = len(Y_ind)\n",
    "    print(\"ROWS_X \\n\", rows_x, \"\\n\")\n",
    "\n",
    "    X = np.array([dat[i:rows_x + i] for i in range(time_step)]).T\n",
    "\n",
    "    rand = np.random.RandomState(seed=13)\n",
    "    idx = rand.permutation(rows_x)\n",
    "    \n",
    "    split = int(train_percent * rows_x)\n",
    "\n",
    "    train_ind, test_ind = idx[:split], idx[split:]\n",
    "    trainX = X[train_ind]\n",
    "    trainY = Y[train_ind]\n",
    "    testX = X[test_ind]\n",
    "    testY = Y[test_ind]\n",
    "    \n",
    "  \n",
    "    trainX = trainX.reshape(-1, time_step, 1)\n",
    "    testX = testX.reshape(-1, time_step, 1)\n",
    "    \n",
    "\n",
    "    trainX = torch.tensor(trainX, dtype=torch.float32)\n",
    "    trainY = torch.tensor(trainY, dtype=torch.float32)\n",
    "    testX = torch.tensor(testX, dtype=torch.float32)\n",
    "    testY = torch.tensor(testY, dtype=torch.float32)\n",
    "\n",
    "    print(f\"TrainX{trainX.shape} \\n TrainY{trainY.shape}\")\n",
    "    \n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Before creating RNN things to remember\n",
    "###### The RNN model expects the input to have a 3d shape\n",
    "###### i.e (batchsize,sequence_lenght,input_size) we have the sequence lenght and input size \n",
    "###### we need a  batch  dimension so  we use unsqueeze function  from  pytorch  to  add  it \n",
    "###### and  same we  need  a batch dimesnion  for y  while  we  pass it in  criterion function \n",
    "###### inshort we do it for the rnn model compatibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR SHAPE torch.Size([10])\n",
      "adding batch  dimension torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "rd_tensor = [0,0.01136364,0.02272727 ,0.04545455 ,0.07954545 ,0.13636364,0.22727273, 0.375 ,0.61363636,1]\n",
    "rd_tensor = torch.tensor(rd_tensor)\n",
    "print(f\"TENSOR SHAPE {rd_tensor.shape}\")\n",
    "print(f\"adding batch  dimension {rd_tensor.unsqueeze(0).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLE RNN MODEL\n"
     ]
    }
   ],
   "source": [
    "class simpleRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(simpleRNN,self).__init__()\n",
    "        self.rnn = nn.RNN(input_size,hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out,_ = self.rnn(x)\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "    \n",
    "print(\"SIMPLE RNN MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_X \n",
      " 1180 \n",
      "\n",
      "TrainXtorch.Size([944, 20, 1]) \n",
      " TrainYtorch.Size([944])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1/30: 100%|██████████| 944/944 [00:00<00:00, 1153.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2/30: 100%|██████████| 944/944 [00:00<00:00, 1163.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3/30: 100%|██████████| 944/944 [00:00<00:00, 1155.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 4/30: 100%|██████████| 944/944 [00:00<00:00, 1153.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 5/30: 100%|██████████| 944/944 [00:00<00:00, 1172.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 6/30: 100%|██████████| 944/944 [00:00<00:00, 1166.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 7/30: 100%|██████████| 944/944 [00:00<00:00, 1174.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 8/30: 100%|██████████| 944/944 [00:00<00:00, 1188.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 9/30: 100%|██████████| 944/944 [00:00<00:00, 1188.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 10/30: 100%|██████████| 944/944 [00:00<00:00, 1191.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 11/30: 100%|██████████| 944/944 [00:00<00:00, 1173.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 12/30: 100%|██████████| 944/944 [00:00<00:00, 1158.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 13/30: 100%|██████████| 944/944 [00:00<00:00, 1195.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 14/30: 100%|██████████| 944/944 [00:00<00:00, 1181.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 15/30: 100%|██████████| 944/944 [00:00<00:00, 1191.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 16/30: 100%|██████████| 944/944 [00:00<00:00, 1192.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 17/30: 100%|██████████| 944/944 [00:00<00:00, 1128.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 18/30: 100%|██████████| 944/944 [00:00<00:00, 1164.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 19/30: 100%|██████████| 944/944 [00:00<00:00, 1186.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 20/30: 100%|██████████| 944/944 [00:00<00:00, 1188.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 21/30: 100%|██████████| 944/944 [00:00<00:00, 1190.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 22/30: 100%|██████████| 944/944 [00:00<00:00, 1177.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 23/30: 100%|██████████| 944/944 [00:00<00:00, 1185.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 24/30: 100%|██████████| 944/944 [00:00<00:00, 1175.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 25/30: 100%|██████████| 944/944 [00:00<00:00, 1175.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 26/30: 100%|██████████| 944/944 [00:00<00:00, 1184.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 27/30: 100%|██████████| 944/944 [00:00<00:00, 1178.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 28/30: 100%|██████████| 944/944 [00:00<00:00, 1179.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 29/30: 100%|██████████| 944/944 [00:00<00:00, 1173.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 30/30: 100%|██████████| 944/944 [00:00<00:00, 1150.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 0.0005\n",
      "Test set MSE = 0.001966223120689392\n",
      "Train set MSE = 0.001585272024385631\n"
     ]
    }
   ],
   "source": [
    "time_steps = 20\n",
    "hidden_size = 2\n",
    "epochs = 30\n",
    "train_percent = 0.8\n",
    "total_fib_numbers = 1200\n",
    "\n",
    "trainX,trainY,testX,testY = get_fib_XY(total_fib_numbers,time_steps,train_percent)\n",
    "model = simpleRNN(input_size=1,hidden_size=hidden_size,output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i  in tqdm(range(len(trainX)),desc=f\"EPOCH {epoch + 1}/{epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(trainX[i].unsqueeze(0)) # adding batch dimension\n",
    "        loss = criterion(outputs,trainY[i].unsqueeze(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(trainX):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "train_mse = criterion(model(trainX), trainY).item()\n",
    "test_mse = criterion(model(testX), testY).item()\n",
    "\n",
    "print(\"Test set MSE =\", test_mse)\n",
    "print(\"Train set MSE =\", train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
