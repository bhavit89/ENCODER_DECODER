{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN With Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fib_seq(n,scaled_data=True):\n",
    "    seq = np.zeros(n)\n",
    "\n",
    "    fib_n1 = 0.0\n",
    "    fib_n = 1.0\n",
    "\n",
    "    for i in  range(n):\n",
    "        seq[i] = fib_n1 + fib_n\n",
    "        fib_n1 = fib_n\n",
    "        fib_n = seq[i]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) if scaled_data else None\n",
    "    if scaled_data:\n",
    "        seq = scaler.fit_transform(seq.reshape(-1,1)).flatten()\n",
    "    \n",
    "    return seq ,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fib_XY(total_fib_numbers, time_step, train_percent, scaled_data=True):\n",
    "    dat, scaler = get_fib_seq(total_fib_numbers, scaled_data)\n",
    "    Y_ind = np.arange(time_step, len(dat), 1)\n",
    "    \n",
    "\n",
    "    Y = dat[Y_ind]\n",
    "    rows_x = len(Y_ind)\n",
    "    print(\"ROWS_X \\n\", rows_x, \"\\n\")\n",
    "\n",
    "    X = np.array([dat[i:rows_x + i] for i in range(time_step)]).T\n",
    "\n",
    "    rand = np.random.RandomState(seed=13)\n",
    "    idx = rand.permutation(rows_x)\n",
    "    \n",
    "    split = int(train_percent * rows_x)\n",
    "\n",
    "    train_ind, test_ind = idx[:split], idx[split:]\n",
    "    trainX = X[train_ind]\n",
    "    trainY = Y[train_ind]\n",
    "    testX = X[test_ind]\n",
    "    testY = Y[test_ind]\n",
    "    \n",
    "  \n",
    "    trainX = trainX.reshape(-1, time_step, 1)\n",
    "    testX = testX.reshape(-1, time_step, 1)\n",
    "    \n",
    "\n",
    "    trainX = torch.tensor(trainX, dtype=torch.float32)\n",
    "    trainY = torch.tensor(trainY, dtype=torch.float32)\n",
    "    testX = torch.tensor(testX, dtype=torch.float32)\n",
    "    testY = torch.tensor(testY, dtype=torch.float32)\n",
    "\n",
    "    print(f\"TrainX{trainX.shape} \\n TrainY{trainY.shape}\")\n",
    "    \n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention_mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(Attention,self).__init__()\n",
    "\n",
    "        # attention weight and bias\n",
    "        self.attention_weight = nn.Parameter(torch.rand(input_dim,1))\n",
    "        self.attention_bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = torch.tanh(torch.matmul(x, self.attention_weight) + self.attention_bias)\n",
    "        e = e.squeeze(-1)\n",
    "\n",
    "        # Compute the weights\n",
    "        alpha = F.softmax(e, dim=1)\n",
    "        alpha = alpha.unsqueeze(-1)\n",
    "\n",
    "        # Compute the context vector\n",
    "        context = torch.mul(x, alpha)\n",
    "        context = torch.sum(context, dim=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNWithAttention(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNNWithAttention,self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size,hidden_size,batch_first=True)\n",
    "        # defining attention layer we coded\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rnn_out ,_ = self.rnn(x)\n",
    "        context = self.attention(rnn_out)\n",
    "        output = self.fc(context)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_X \n",
      " 1180 \n",
      "\n",
      "TrainXtorch.Size([944, 20, 1]) \n",
      " TrainYtorch.Size([944])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1/30: 100%|██████████| 944/944 [00:03<00:00, 273.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2/30: 100%|██████████| 944/944 [00:03<00:00, 287.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3/30: 100%|██████████| 944/944 [00:02<00:00, 318.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 4/30: 100%|██████████| 944/944 [00:03<00:00, 313.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 5/30: 100%|██████████| 944/944 [00:02<00:00, 318.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 6/30: 100%|██████████| 944/944 [00:02<00:00, 325.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 7/30: 100%|██████████| 944/944 [00:02<00:00, 316.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 8/30: 100%|██████████| 944/944 [00:02<00:00, 324.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 9/30: 100%|██████████| 944/944 [00:02<00:00, 325.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 10/30: 100%|██████████| 944/944 [00:02<00:00, 325.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 11/30: 100%|██████████| 944/944 [00:03<00:00, 307.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 12/30: 100%|██████████| 944/944 [00:02<00:00, 323.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 13/30: 100%|██████████| 944/944 [00:03<00:00, 311.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 14/30: 100%|██████████| 944/944 [00:03<00:00, 291.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 15/30: 100%|██████████| 944/944 [00:04<00:00, 232.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 16/30: 100%|██████████| 944/944 [00:03<00:00, 255.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 17/30: 100%|██████████| 944/944 [00:04<00:00, 216.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 18/30: 100%|██████████| 944/944 [00:03<00:00, 246.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 19/30: 100%|██████████| 944/944 [00:02<00:00, 315.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 20/30: 100%|██████████| 944/944 [00:02<00:00, 319.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 21/30: 100%|██████████| 944/944 [00:03<00:00, 300.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 22/30: 100%|██████████| 944/944 [00:03<00:00, 308.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 23/30: 100%|██████████| 944/944 [00:03<00:00, 293.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 24/30: 100%|██████████| 944/944 [00:03<00:00, 283.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 25/30: 100%|██████████| 944/944 [00:03<00:00, 300.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 26/30: 100%|██████████| 944/944 [00:03<00:00, 297.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 27/30: 100%|██████████| 944/944 [00:03<00:00, 308.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 28/30: 100%|██████████| 944/944 [00:02<00:00, 320.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 29/30: 100%|██████████| 944/944 [00:03<00:00, 310.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 30/30: 100%|██████████| 944/944 [00:02<00:00, 315.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 0.0010\n",
      "Test set MSE = 0.001682108617387712\n",
      "Train set MSE = 0.0013740231515839696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_steps = 20\n",
    "hidden_size = 2\n",
    "epochs = 30\n",
    "train_percent = 0.8\n",
    "total_fib_numbers = 1200\n",
    "\n",
    "trainX,trainY,testX,testY = get_fib_XY(total_fib_numbers,time_steps,train_percent)\n",
    "model = RNNWithAttention(input_size=1,hidden_size=hidden_size,output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i  in tqdm(range(len(trainX)),desc=f\"EPOCH {epoch + 1}/{epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(trainX[i].unsqueeze(0)) # adding batch dimension\n",
    "        loss = criterion(outputs,trainY[i].unsqueeze(0))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(trainX):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "train_mse = criterion(model(trainX), trainY).item()\n",
    "test_mse = criterion(model(testX), testY).item()\n",
    "\n",
    "print(\"Test set MSE =\", test_mse)\n",
    "print(\"Train set MSE =\", train_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
